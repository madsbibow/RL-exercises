{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q-learn-and-friends.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMX3eEQq1vCEm3b+47aHAOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madsbibow/RL-exercises/blob/master/Q_learn_and_friends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K-jsysoUpio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2cHqFaGWph8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MDP:\n",
        "    '''A simple MDP class.  It includes the following members'''\n",
        "\n",
        "    def __init__(self,T,R,discount):\n",
        "        '''Constructor for the MDP class\n",
        "\n",
        "        Inputs:\n",
        "        T -- Transition function: |A| x |S| x |S'| array\n",
        "        R -- Reward function: |A| x |S| array\n",
        "        discount -- discount factor: scalar in [0,1)\n",
        "\n",
        "        The constructor verifies that the inputs are valid and sets\n",
        "        corresponding variables in a MDP object'''\n",
        "\n",
        "        assert T.ndim == 3, \"Invalid transition function: it should have 3 dimensions\"\n",
        "        self.nActions = T.shape[0]\n",
        "        self.nStates = T.shape[1]\n",
        "        assert T.shape == (self.nActions,self.nStates,self.nStates), \"Invalid transition function: it has dimensionality \" + repr(T.shape) + \", but it should be (nActions,nStates,nStates)\"\n",
        "        assert (abs(T.sum(2)-1) < 1e-5).all(), \"Invalid transition function: some transition probability does not equal 1\"\n",
        "        self.T = T\n",
        "        assert R.ndim == 2, \"Invalid reward function: it should have 2 dimensions\" \n",
        "        assert R.shape == (self.nActions,self.nStates), \"Invalid reward function: it has dimensionality \" + repr(R.shape) + \", but it should be (nActions,nStates)\"\n",
        "        self.R = R\n",
        "        assert 0 <= discount < 1, \"Invalid discount factor: it should be in [0,1)\"\n",
        "        self.discount = discount\n",
        "        self.state_range = range(mdp.nStates)\n",
        "\n",
        "    def valueIteration(self,initialV,nIterations=np.inf,tolerance=0.01):\n",
        "        '''Value iteration procedure\n",
        "        V <-- max_a R^a + gamma T^a V\n",
        "\n",
        "        Inputs:\n",
        "        initialV -- Initial value function: array of |S| entries\n",
        "        nIterations -- limit on the # of iterations: scalar (default: infinity)\n",
        "        tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
        "\n",
        "        Outputs: \n",
        "        V -- Value function: array of |S| entries\n",
        "        iterId -- # of iterations performed: scalar\n",
        "        epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
        "        \n",
        "        # temporary values to ensure that the code compiles until this\n",
        "        # function is coded\n",
        "        assert initialV.shape == (self.nStates,), \"Invalid initial value: it has dimensionality {}, but is should be {}\".format(initialV.shape,(self.nStates,))   \n",
        "        V = initialV \n",
        "        iterId = 0\n",
        "        epsilon = 0\n",
        "\n",
        "        while iterId <= nIterations:\n",
        "          V_old = V.copy()\n",
        "          V     = (self.R + self.discount*np.dot(self.T, V)).max(0)\n",
        "          \n",
        "          epsilon = np.abs(V - V_old).max()\n",
        "          if epsilon < tolerance:\n",
        "            break\n",
        "          iterId = iterId + 1\n",
        "        \n",
        "        return [V,iterId,epsilon]\n",
        "\n",
        "    def extractPolicy(self,V):\n",
        "        '''Procedure to extract a policy from a value function\n",
        "        pi <-- argmax_a R^a + gamma T^a V\n",
        "\n",
        "        Inputs:\n",
        "        V -- Value function: array of |S| entries\n",
        "\n",
        "        Output:\n",
        "        policy -- Policy: array of |S| entries'''\n",
        "\n",
        "        # temporary values to ensure that the code compiles until this\n",
        "        # function is coded\n",
        "        assert V.shape == (self.nStates,), \"Invalid initial value: it has dimensionality {}, but is should be {}\".format(V.shape,(self.nStates,))\n",
        "        policy = (self.R + self.discount*np.dot(self.T, V)).argmax(0)\n",
        "\n",
        "        return policy \n",
        "\n",
        "    def evaluatePolicy(self,policy):\n",
        "        '''Evaluate a policy by solving a system of linear equations\n",
        "        V^pi = R^pi + gamma T^pi V^pi\n",
        "\n",
        "        Input:\n",
        "        policy -- Policy: array of |S| entries\n",
        "\n",
        "        Ouput:\n",
        "        V -- Value function: array of |S| entries'''\n",
        "\n",
        "        # temporary values to ensure that the code compiles until this\n",
        "        # function is coded\n",
        "\n",
        "        R_pi = self.R[policy,self.state_range]\n",
        "        T_pi = self.T[policy,self.state_range,:]\n",
        "        V = np.linalg.solve(np.eye(self.nStates)-self.discount*T_pi,R_pi) \n",
        "        \n",
        "        return V\n",
        "        \n",
        "    # def policyIteration(self,initialPolicy,nIterations=np.inf):\n",
        "    #     '''Policy iteration procedure: alternate between policy\n",
        "    #     evaluation (solve V^pi = R^pi + gamma T^pi V^pi) and policy\n",
        "    #     improvement (pi <-- argmax_a R^a + gamma T^a V^pi).\n",
        "\n",
        "    #     Inputs:\n",
        "    #     initialPolicy -- Initial policy: array of |S| entries\n",
        "    #     nIterations -- limit on # of iterations: scalar (default: inf)\n",
        "\n",
        "    #     Outputs: \n",
        "    #     policy -- Policy: array of |S| entries\n",
        "    #     V -- Value function: array of |S| entries\n",
        "    #     iterId -- # of iterations peformed by modified policy iteration: scalar'''\n",
        "\n",
        "    #     # temporary values to ensure that the code compiles until this\n",
        "    #     # function is coded\n",
        "    #     policy = np.zeros(self.nStates)\n",
        "    #     V = np.zeros(self.nStates)\n",
        "    #     iterId = 0\n",
        "\n",
        "    #     return [policy,V,iterId]\n",
        "            \n",
        "    # def evaluatePolicyPartially(self,policy,initialV,nIterations=np.inf,tolerance=0.01):\n",
        "    #     '''Partial policy evaluation:\n",
        "    #     Repeat V^pi <-- R^pi + gamma T^pi V^pi\n",
        "\n",
        "    #     Inputs:\n",
        "    #     policy -- Policy: array of |S| entries\n",
        "    #     initialV -- Initial value function: array of |S| entries\n",
        "    #     nIterations -- limit on the # of iterations: scalar (default: infinity)\n",
        "    #     tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
        "\n",
        "    #     Outputs: \n",
        "    #     V -- Value function: array of |S| entries\n",
        "    #     iterId -- # of iterations performed: scalar\n",
        "    #     epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
        "\n",
        "    #     # temporary values to ensure that the code compiles until this\n",
        "    #     # function is coded\n",
        "    #     V = np.zeros(self.nStates)\n",
        "    #     iterId = 0\n",
        "    #     epsilon = 0\n",
        "\n",
        "    #     return [V,iterId,epsilon]\n",
        "\n",
        "    # def modifiedPolicyIteration(self,initialPolicy,initialV,nEvalIterations=5,nIterations=np.inf,tolerance=0.01):\n",
        "    #     '''Modified policy iteration procedure: alternate between\n",
        "    #     partial policy evaluation (repeat a few times V^pi <-- R^pi + gamma T^pi V^pi)\n",
        "    #     and policy improvement (pi <-- argmax_a R^a + gamma T^a V^pi)\n",
        "\n",
        "    #     Inputs:\n",
        "    #     initialPolicy -- Initial policy: array of |S| entries\n",
        "    #     initialV -- Initial value function: array of |S| entries\n",
        "    #     nEvalIterations -- limit on # of iterations to be performed in each partial policy evaluation: scalar (default: 5)\n",
        "    #     nIterations -- limit on # of iterations to be performed in modified policy iteration: scalar (default: inf)\n",
        "    #     tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
        "\n",
        "    #     Outputs: \n",
        "    #     policy -- Policy: array of |S| entries\n",
        "    #     V -- Value function: array of |S| entries\n",
        "    #     iterId -- # of iterations peformed by modified policy iteration: scalar\n",
        "    #     epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
        "\n",
        "    #     # temporary values to ensure that the code compiles until this\n",
        "    #     # function is coded\n",
        "    #     policy = np.zeros(self.nStates)\n",
        "    #     V = np.zeros(self.nStates)\n",
        "    #     iterId = 0\n",
        "    #     epsilon = 0\n",
        "\n",
        "    #     return [policy,V,iterId,epsilon]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPMmwfYTZ15o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Construct simple MDP as described in Lecture 2a Slides 13-14'''\n",
        "# Transition function: |A| x |S| x |S'| array\n",
        "T = np.array([[[0.5,0.5,0,0],[0,1,0,0],[0.5,0.5,0,0],[0,1,0,0]],[[1,0,0,0],[0.5,0,0,0.5],[0.5,0,0.5,0],[0,0,0.5,0.5]]])\n",
        "# Reward function: |A| x |S| array\n",
        "R = np.array([[0,0,10,10],[0,0,10,10]])\n",
        "# Discount factor: scalar in [0,1)\n",
        "discount = 0.9        \n",
        "# MDP object\n",
        "mdp = MDP(T,R,discount)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAwfRysKbOst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "491fb98f-92a5-4994-a571-e5932c0d2136"
      },
      "source": [
        "#mdp.R\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0, 10, 10],\n",
              "       [ 0,  0, 10, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNpybCEGaFw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6090c370-2f13-4de9-baa5-f4c7917afda2"
      },
      "source": [
        "[V,nIterations,epsilon] = mdp.valueIteration(initialV=np.zeros(mdp.nStates))\n",
        "policy = mdp.extractPolicy(V)\n",
        "\n",
        "print('Iterations {}, epsilon{}'.format(nIterations,epsilon))\n",
        "print('V',V)\n",
        "print('policy',policy)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iterations 57, epsilon0.009860138819838937\n",
            "V [31.49636306 38.51527513 43.935435   54.1128575 ]\n",
            "policy [0 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zh51-dsmcwW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0fd8b5b7-4eed-4a63-91ad-28cfe2197995"
      },
      "source": [
        "V_CHECK = mdp.evaluatePolicy(policy)\n",
        "print(V_CHECK)\n",
        "V = mdp.evaluatePolicy(np.array([1,0,1,0]))\n",
        "print(V)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[31.58510431 38.60401638 44.02417625 54.20159875]\n",
            "[-0.         -0.         18.18181818 10.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMpEA6emb09u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2b5631ef-1806-4554-9132-88e75572b68b"
      },
      "source": [
        "#V = np.zeros(mdp.nStates)\n",
        "print(policy)\n",
        "print(mdp.R)\n",
        "\n",
        ".sum(1)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1]\n",
            "[[ 0  0 10 10]\n",
            " [ 0  0 10 10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OhFOr4BaD18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Test each procedure'''\n",
        "\n",
        "[policy,V,iterId] = mdp.policyIteration(np.array([0,0,0,0]))\n",
        "[V,iterId,epsilon] = mdp.evaluatePolicyPartially(np.array([1,0,1,0]),np.array([0,10,0,13]))\n",
        "[policy,V,iterId,tolerance] = mdp.modifiedPolicyIteration(np.array([1,0,1,0]),np.array([0,10,0,13]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}